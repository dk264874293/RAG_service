# RAG æ¶æ„å®æ–½å·¥ä½œè®¡åˆ’

> **å®æ–½èŒƒå›´**: Phase 1-6
> **æŠ€æœ¯æ ˆ**: FAISS-CPU + DashScope Embeddings
> **é¢„è®¡æ—¶é—´**: 5-6 å¤©

---

## ğŸ“Š å®æ–½æ¦‚è§ˆ

### ç›®æ ‡
ä¸º RAG æœåŠ¡æ·»åŠ å®Œæ•´çš„å‘é‡å­˜å‚¨å’Œæ£€ç´¢èƒ½åŠ›ï¼š
1. åˆ›å»ºå‘é‡æœåŠ¡æ¨¡å—
2. å®ç°æ–‡æ¡£å‘é‡åŒ–æµç¨‹
3. é›†æˆ FAISS å‘é‡å­˜å‚¨
4. æä¾›è¯­ä¹‰æ£€ç´¢ API

### æŠ€æœ¯æ ˆ
- **å‘é‡å­˜å‚¨**: FAISS-CPU (`faiss-cpu`)
- **åµŒå…¥æ¨¡å‹**: DashScope (`text-embedding-v2`)
- **å‘é‡ç»´åº¦**: 1536

---

## ğŸ¯ æ ¸å¿ƒåŸåˆ™

### TDD æ–¹æ³•
- æ¯ä¸ªä»»åŠ¡å…ˆç¼–å†™/æ›´æ–°æµ‹è¯•
- ä½¿ç”¨ `agent-executable` éªŒè¯ï¼ˆä¸ä¾èµ–æ‰‹åŠ¨æ£€æŸ¥ï¼‰
- API ç«¯ç‚¹ä½¿ç”¨ Playwright è‡ªåŠ¨åŒ–æµ‹è¯•

### å¹¶è¡Œæ‰§è¡Œç­–ç•¥
- **Wave 1**: åˆ›å»ºç›®å½•ç»“æ„å’Œç±»å‹å®šä¹‰ï¼ˆå¯å¹¶è¡Œï¼‰
- **Wave 2**: å®ç°åµŒå…¥æœåŠ¡ï¼ˆä¾èµ– Wave 1ï¼‰
- **Wave 3**: å®ç°å‘é‡å­˜å‚¨ç®¡ç†å™¨ï¼ˆä¾èµ– Wave 1-2ï¼‰
- **Wave 4**: å®ç°æ–‡æ¡£ç´¢å¼•å™¨å’Œæ£€ç´¢æœåŠ¡ï¼ˆä¾èµ– Wave 1-3ï¼‰
- **Wave 5**: é›†æˆåˆ° DocumentServiceï¼ˆä¾èµ– Wave 4ï¼‰
- **Wave 6**: åˆ›å»ºæ£€ç´¢ API ç«¯ç‚¹ï¼ˆä¾èµ– Wave 5ï¼‰

---

## ğŸ“‹ è¯¦ç»†å®æ–½ä»»åŠ¡

### Wave 1: åˆ›å»ºå‘é‡æœåŠ¡æ¨¡å—åŸºç¡€ç»“æ„

#### ä»»åŠ¡ 1.1: åˆ›å»º src/vector/ ç›®å½•ç»“æ„

**What to do**:
- åˆ›å»º `src/vector/` ç›®å½•
- åˆ›å»º `src/vector/__init__.py`
- åˆ›å»º `src/vector/types.py`

**Must NOT do**:
- ä¸è¦ä½¿ç”¨ä¸­æ–‡æ³¨é‡Šæˆ–æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆä»£ç å®¡æŸ¥å·²æç¤ºï¼‰
- ä¸è¦åˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼ˆPhase 4 æš‚æ—¶ä¸å®æ–½æµ‹è¯•ï¼‰

**Recommended Agent Profile**:
- **Category**: `unspecified-low`
- **Skills**: `["git-master"]`
- **Reasoning**: åŸºç¡€ç›®å½•åˆ›å»ºå’Œç®€å•ä»£ç ç¼–å†™

**Parallelization**:
- **Can Run In Parallel**: NOï¼ˆé¡ºåºæ‰§è¡Œï¼‰
- **Parallel Group**: Wave 1 Sequential
- **Blocks**: Wave 2, 3, 4, 5, 6
- **Blocked By**: None

**References**:

**Pattern References**:
- `src/extractor/__init__.py` - æ¨¡å—åˆå§‹åŒ–æ¨¡å¼
- `src/models/types.py` - ç±»å‹å®šä¹‰æ¨¡å¼

**Acceptance Criteria**:

**Automated Verification (using Bash)**:
```bash
# Agent executes:
mkdir -p src/vector && echo "Directory created"

# Verify:
test -d src/vector && echo "PASS: Directory exists" || echo "FAIL: Directory not found"

# Verify files exist:
test -f src/vector/__init__.py && echo "PASS: __init__.py exists" || echo "FAIL: __init__.py missing"
test -f src/vector/types.py && echo "PASS: types.py exists" || echo "FAIL: types.py missing"
```

**Commit**: NO

---

#### ä»»åŠ¡ 1.2: å®ç°å‘é‡æœåŠ¡ç±»å‹å®šä¹‰

**What to do**:
- åœ¨ `src/vector/types.py` ä¸­å®šä¹‰å‘é‡ç›¸å…³ç±»å‹
- å®šä¹‰ `VectorSearchResult` ç±»ï¼ˆåŒ…å«æ–‡æ¡£å’Œåˆ†æ•°ï¼‰
- å®šä¹‰ `IndexStats` ç±»ï¼ˆç´¢å¼•ç»Ÿè®¡ä¿¡æ¯ï¼‰

**Must NOT do**:
- ä¸è¦å®ç°å¤æ‚çš„åµŒå¥—ç±»å‹
- ä¸è¦æ·»åŠ æœªä½¿ç”¨çš„ç±»å‹

**Recommended Agent Profile**:
- **Category**: `unspecified-low`
- **Skills**: `[]`
- **Reasoning**: ç®€å•ç±»å‹å®šä¹‰ï¼Œä¸éœ€è¦ç‰¹æ®ŠæŠ€èƒ½

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 1 Sequential
- **Blocks**: Wave 2, 3, 4, 5, 6
- **Blocked By**: Task 1.1

**References**:

**Pattern References**:
- `src/models/document.py:Document` - Pydantic æ¨¡å‹å®šä¹‰æ¨¡å¼
- `src/schemas/upload.py:UploadResponse` - å“åº”æ¨¡å‹å®šä¹‰æ¨¡å¼

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
from src.vector.types import VectorSearchResult, IndexStats
print('Types imported successfully')

# Test VectorSearchResult
result = VectorSearchResult(
    doc_id='test',
    content='test content',
    metadata={},
    score=0.8
)
print(f'PASS: VectorSearchResult created - doc_id={result.doc_id}')

# Test IndexStats
stats = IndexStats(
    total_vectors=100,
    index_path='./data/faiss_index',
    dimension=1536
)
print(f'PASS: IndexStats created - total_vectors={stats.total_vectors}')
"

# Expected output:
# Types imported successfully
# PASS: VectorSearchResult created - doc_id=test
# PASS: IndexStats created - total_vectors=100
```

**Commit**: NO

---

### Wave 2: å®ç°åµŒå…¥æœåŠ¡

#### ä»»åŠ¡ 2.1: å®ç° EmbeddingService

**What to do**:
- åˆ›å»º `src/vector/embed_service.py`
- å®ç° `EmbeddingService` ç±»
- å®ç° `embed_text()` æ–¹æ³•ï¼ˆå•ä¸ªæ–‡æœ¬åµŒå…¥ï¼‰
- å®ç° `embed_batch()` æ–¹æ³•ï¼ˆæ‰¹é‡åµŒå…¥ï¼‰
- å®ç° `get_dimension()` æ–¹æ³•

**Must NOT do**:
- ä¸è¦åœ¨ __init__ ä¸­è°ƒç”¨ APIï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
- ä¸è¦ç¡¬ç¼–ç  API Keyï¼ˆä½¿ç”¨ config.dashscope_api_keyï¼‰

**Recommended Agent Profile**:
- **Category**: `unspecified-low`
- **Skills**: `[]`
- **Reasoning**: æ ‡å‡†æœåŠ¡ç±»å®ç°ï¼Œä½¿ç”¨ langchain_community é›†æˆ

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 2 Sequential
- **Blocks**: Wave 3, 4, 5, 6
- **Blocked By**: Wave 1 (types.py ä¾èµ–)

**References**:

**Pattern References**:
- `chain/memory/faiss_mem.py:FAISSMemoryManager.__init__` - DashScope åµŒå…¥åˆå§‹åŒ–æ¨¡å¼
- `chain/dashscope_embedding.py:25` - DashScopeEmbeddings ä½¿ç”¨ç¤ºä¾‹

**API/Type References**:
- `langchain_community.embeddings.DashScopeEmbeddings` - åµŒå…¥æ¨¡å‹ç±»
- `config.py:dashscope_api_key` - API Key é…ç½®

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
import asyncio
from src.vector.embed_service import EmbeddingService
from config import settings

async def test():
    service = EmbeddingService(settings)
    
    # Test dimension
    dim = service.get_dimension()
    print(f'Dimension: {dim}')
    assert dim == 1536, f'FAIL: Expected 1536, got {dim}'
    print('PASS: Dimension is correct')
    
    # Test single embedding
    text = 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬'
    vector = await service.embed_text(text)
    print(f'Vector length: {len(vector)}')
    assert len(vector) == 1536, f'FAIL: Expected 1536, got {len(vector)}'
    assert all(isinstance(v, (int, float)) for v in vector), 'FAIL: Vector contains non-numeric values'
    print('PASS: Single embedding works')
    
    # Test batch embedding
    texts = ['æ–‡æœ¬1', 'æ–‡æœ¬2', 'æ–‡æœ¬3']
    vectors = await service.embed_batch(texts)
    print(f'Batch size: {len(vectors)}')
    assert len(vectors) == 3, f'FAIL: Expected 3, got {len(vectors)}'
    assert all(len(v) == 1536 for v in vectors), 'FAIL: Batch vectors have wrong dimension'
    print('PASS: Batch embedding works')

asyncio.run(test())
"

# Expected output:
# Dimension: 1536
# PASS: Dimension is correct
# Vector length: 1536
# PASS: Single embedding works
# Batch size: 3
# PASS: Batch embedding works
```

**Commit**: NO

---

### Wave 3: å®ç°å‘é‡å­˜å‚¨ç®¡ç†å™¨

#### ä»»åŠ¡ 3.1: å®ç° FAISSVectorStore

**What to do**:
- åˆ›å»º `src/vector/vector_store.py`
- å®ç° `FAISSVectorStore` ç±»
- å®ç° `_initialize()` æ–¹æ³•ï¼ˆåŠ è½½æˆ–åˆ›å»ºç´¢å¼•ï¼‰
- å®ç° `_load_existing_index()` æ–¹æ³•
- å®ç° `_create_new_index()` æ–¹æ³•
- å®ç° `add_documents()` æ–¹æ³•
- å®ç° `similarity_search()` æ–¹æ³•
- å®ç° `similarity_search_with_score()` æ–¹æ³•
- å®ç° `save_index()` æ–¹æ³•
- å®ç° `get_stats()` æ–¹æ³•

**Must NOT do**:
- ä¸è¦åœ¨æ¯æ¬¡ add_documents åéƒ½ save_indexï¼ˆæ‰¹é‡æ“ä½œåç»Ÿä¸€ä¿å­˜ï¼‰
- ä¸è¦ä½¿ç”¨ä¸­æ–‡æ—¥å¿—æ¶ˆæ¯ï¼ˆä½¿ç”¨è‹±æ–‡ï¼‰

**Recommended Agent Profile**:
- **Category**: `unspecified-high`
- **Skills**: `[]`
- **Reasoning**: å¤æ‚çš„å‘é‡å­˜å‚¨ç®¡ç†ï¼Œéœ€è¦é”™è¯¯å¤„ç†å’ŒçŠ¶æ€ç®¡ç†

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 3 Sequential
- **Blocks**: Wave 4, 5, 6
- **Blocked By**: Wave 1-2 (ä¾èµ– EmbeddingService)

**References**:

**Pattern References**:
- `chain/memory/faiss_mem.py:FAISSMemoryManager` - FAISS ç®¡ç†å™¨å®ç°æ¨¡å¼
- `chain/memory/faiss_mem.py:54-98` - ç´¢å¼•åˆå§‹åŒ–å’ŒåŠ è½½é€»è¾‘
- `chain/memory/faiss_mem.py:115-140` - add_documents å®ç°
- `chain/memory/faiss_mem.py:142-172` - similarity_search å®ç°

**API/Type References**:
- `langchain_community.vectorstores.FAISS` - FAISS å‘é‡å­˜å‚¨
- `langchain_core.documents.Document` - Langchain æ–‡æ¡£æ¨¡å‹
- `config.py:faiss_index_path` - FAISS ç´¢å¼•è·¯å¾„é…ç½®

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
import asyncio
from src.vector.embed_service import EmbeddingService
from src.vector.vector_store import FAISSVectorStore
from config import settings

async def test():
    # Initialize services
    embedding_service = EmbeddingService(settings)
    store = FAISSVectorStore(settings, embedding_service)
    
    # Test stats
    stats = store.get_stats()
    print(f'Total vectors: {stats[\"total_vectors\"]}')
    assert 'total_vectors' in stats, 'FAIL: Missing total_vectors in stats'
    assert stats['total_vectors'] >= 1, 'FAIL: Index should have at least 1 vector (init doc)'
    print('PASS: Stats accessible')
    
    # Test similarity_search
    results = await store.similarity_search('æµ‹è¯•æŸ¥è¯¢', k=2)
    print(f'Search results: {len(results)}')
    assert isinstance(results, list), 'FAIL: Results should be a list'
    print('PASS: Similarity search works')
    
    # Test save_index
    saved = await store.save_index()
    assert saved is True, 'FAIL: save_index should return True'
    print('PASS: Index saved')

asyncio.run(test())
"

# Expected output:
# Total vectors: 1
# PASS: Stats accessible
# Search results: 1
# PASS: Similarity search works
# PASS: Index saved
```

**Commit**: NO

---

### Wave 4: å®ç°æ–‡æ¡£ç´¢å¼•å™¨å’Œæ£€ç´¢æœåŠ¡

#### ä»»åŠ¡ 4.1: å®ç° DocumentIndexer

**What to do**:
- åˆ›å»º `src/vector/document_indexer.py`
- å®ç° `DocumentIndexer` ç±»
- å®ç° `index_document()` æ–¹æ³•ï¼ˆå°†æ–‡æ¡£å‘é‡åŒ–å¹¶å­˜å‚¨ï¼‰
- å®ç° `get_index_stats()` æ–¹æ³•

**Must NOT do**:
- ä¸è¦å®ç° `delete_document()`ï¼ˆFAISS ä¸æ”¯æŒåˆ é™¤ï¼‰
- ä¸è¦åœ¨æ¯æ¬¡ index_document åéƒ½ saveï¼ˆæ‰¹é‡æ“ä½œåç»Ÿä¸€ä¿å­˜ï¼‰

**Recommended Agent Profile**:
- **Category**: `unspecified-low`
- **Skills**: `[]`
- **Reasoning**: ç´¢å¼•æœåŠ¡å®ç°ï¼Œä¾èµ– EmbeddingService å’Œ FAISSVectorStore

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 4 Sequential (with Task 4.2)
- **Blocks**: Wave 5, 6
- **Blocked By**: Wave 1-3

**References**:

**Pattern References**:
- `src/service/document_service.py:16-78` - æœåŠ¡ç±»å®ç°æ¨¡å¼
- `chain/memory/faiss_mem.py:115-140` - æ–‡æ¡£æ·»åŠ åˆ°å‘é‡å­˜å‚¨çš„æ¨¡å¼

**API/Type References**:
- `src.models.document:Document` - è‡ªå®šä¹‰æ–‡æ¡£æ¨¡å‹
- `langchain_core.documents.Document` - Langchain æ–‡æ¡£æ¨¡å‹ï¼ˆéœ€è¦è½¬æ¢ï¼‰

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
import asyncio
from src.vector.embed_service import EmbeddingService
from src.vector.vector_store import FAISSVectorStore
from src.vector.document_indexer import DocumentIndexer
from src.models.document import Document
from config import settings

async def test():
    # Initialize services
    embedding_service = EmbeddingService(settings)
    vector_store = FAISSVectorStore(settings, embedding_service)
    indexer = DocumentIndexer(settings, vector_store, embedding_service)
    
    # Test index_document
    docs = [
        Document(page_content='Test content 1', id_='doc1'),
        Document(page_content='Test content 2', id_='doc2')
    ]
    success = await indexer.index_document('test_file', docs)
    print(f'Index success: {success}')
    assert success is True, 'FAIL: index_document should return True'
    print('PASS: Document indexed')
    
    # Verify stats updated
    stats = await indexer.get_index_stats()
    print(f'Total vectors: {stats[\"total_vectors\"]}')
    assert stats['total_vectors'] >= 3, 'FAIL: Should have at least 3 vectors (1 init + 2 docs)'
    print('PASS: Stats updated correctly')

asyncio.run(test())
"

# Expected output:
# Index success: True
# PASS: Document indexed
# Total vectors: 3
# PASS: Stats updated correctly
```

**Commit**: NO

---

#### ä»»åŠ¡ 4.2: å®ç° RetrievalService

**What to do**:
- åˆ›å»º `src/vector/retrieval_service.py`
- å®ç° `RetrievalService` ç±»
- å®ç° `search()` æ–¹æ³•ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
- å®ç° `search_with_scores()` æ–¹æ³•ï¼ˆå¸¦ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰

**Must NOT do**:
- ä¸è¦å®ç°é«˜çº§æ£€ç´¢ï¼ˆhybrid_search, mmr_searchï¼‰ï¼Œåªå®ç°åŸºç¡€çš„å‘é‡æ£€ç´¢

**Recommended Agent Profile**:
- **Category**: `unspecified-low`
- **Skills**: `[]`
- **Reasoning**: æ£€ç´¢æœåŠ¡å®ç°ï¼Œç›¸å¯¹ç®€å•

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 4 Sequential
- **Blocks**: Wave 5, 6
- **Blocked By**: Wave 1-3

**References**:

**Pattern References**:
- `chain/memory/faiss_mem.py:142-172` - similarity_search å®ç°æ¨¡å¼
- `src/service/document_service.py:16-78` - æœåŠ¡ç±»å®ç°æ¨¡å¼

**API/Type References**:
- `src.vector.vector_store:FAISSVectorStore.similarity_search` - å‘é‡æœç´¢æ–¹æ³•
- `src.models.document:Document` - è‡ªå®šä¹‰æ–‡æ¡£æ¨¡å‹

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
import asyncio
from src.vector.embed_service import EmbeddingService
from src.vector.vector_store import FAISSVectorStore
from src.vector.document_indexer import DocumentIndexer
from src.vector.retrieval_service import RetrievalService
from src.models.document import Document
from config import settings

async def test():
    # Initialize and index some documents first
    embedding_service = EmbeddingService(settings)
    vector_store = FAISSVectorStore(settings, embedding_service)
    indexer = DocumentIndexer(settings, vector_store, embedding_service)
    
    docs = [
        Document(page_content='Python is a programming language', id_='doc1'),
        Document(page_content='JavaScript is used for web development', id_='doc2'),
        Document(page_content='Python supports async programming', id_='doc3')
    ]
    await indexer.index_document('test', docs)
    
    # Test retrieval service
    retrieval_service = RetrievalService(settings, vector_store, embedding_service)
    
    # Test search
    results = await retrieval_service.search('Python programming', k=2)
    print(f'Search results: {len(results)}')
    assert len(results) > 0, 'FAIL: Should return at least 1 result'
    assert any('Python' in r.page_content for r in results), 'FAIL: Results should contain Python'
    print('PASS: Search works')
    
    # Test search_with_scores
    results_with_scores = await retrieval_service.search_with_scores('Python', k=2)
    print(f'Search with scores: {len(results_with_scores)}')
    assert len(results_with_scores) > 0, 'FAIL: Should return at least 1 result'
    doc, score = results_with_scores[0]
    assert isinstance(score, (int, float)), 'FAIL: Score should be numeric'
    assert doc.page_content is not None, 'FAIL: Document should have content'
    print(f'PASS: Search with scores works (score={score:.4f})')

asyncio.run(test())
"

# Expected output:
# Search results: 2
# PASS: Search works
# Search with scores: 2
# PASS: Search with scores works (score=0.xxxx)
```

**Commit**: NO

---

### Wave 5: é›†æˆåˆ°ç°æœ‰æœåŠ¡

#### ä»»åŠ¡ 5.1: ä¿®æ”¹ DocumentService

**What to do**:
- ä¿®æ”¹ `src/service/document_service.py`
- åœ¨ `process_document()` æ–¹æ³•æœ«å°¾æ·»åŠ å‘é‡åŒ–æ­¥éª¤
- åœ¨ `process_document()` çš„ except å—ä¸­æ•è·å‘é‡åŒ–å¼‚å¸¸ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰

**Must NOT do**:
- ä¸è¦ä¿®æ”¹ç°æœ‰å¤„ç†æµç¨‹ï¼Œåªåœ¨æœ«å°¾æ·»åŠ 
- ä¸è¦æ”¹å˜è¿”å›å€¼ç»“æ„
- ä¸è¦æ·»åŠ ä¸­æ–‡æ—¥å¿—ï¼ˆä½¿ç”¨è‹±æ–‡ï¼‰

**Recommended Agent Profile**:
- **Category**: `quick`
- **Skills**: `[]`
- **Reasoning**: ç®€å•çš„é›†æˆä¿®æ”¹ï¼Œå‘ç°æœ‰æ–¹æ³•æ·»åŠ ä»£ç 

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 5 Sequential
- **Blocks**: Wave 6
- **Blocked By**: Wave 1-4

**References**:

**Pattern References**:
- `src/service/document_service.py:36-60` - ç°æœ‰å¤„ç†æµç¨‹
- `src/service/document_service.py:63-68` - å¼‚å¸¸å¤„ç†æ¨¡å¼

**Code Location**:
- `src/service/document_service.py:61` - åœ¨ return è¯­å¥ä¹‹å‰æ·»åŠ å‘é‡åŒ–ä»£ç 

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
import asyncio
from src.service.document_service import DocumentService
from config import settings
from pathlib import Path

async def test():
    service = DocumentService(settings)
    
    # Check if the file exists for testing
    test_file = './src/extractor/ocr_module/core/pdfs/25AA0118é‡‡æ ·.pdf'
    if not Path(test_file).exists():
        print('SKIP: Test file not found')
        return
    
    # Process document (this should trigger vectorization)
    success, msg, documents = await service.process_document(
        test_file,
        'test_file_001',
        'test.pdf'
    )
    
    print(f'Success: {success}')
    print(f'message: {msg}')
    print(f'documents: {len(documents)}')
    
    # Verify vectorization happened
    import os
    faiss_dir = './data/faiss_index'
    if os.path.exists(faiss_dir):
        files = os.listdir(faiss_dir)
        print(f'FAISS index files: {files}')
        assert len(files) > 0, 'FAIL: FAISS index should be created'
        print('PASS: Vectorization completed - FAISS index created')
    else:
        print('SKIP: FAISS index not created (may be normal if test file missing)')

asyncio.run(test())
"

# Expected output:
# success: True
# message: å¤„ç†æˆåŠŸ
# documents: X
# FAISS index files: ['index.faiss', 'index.pkl']
# PASS: Vectorization completed - FAISS index created
```

**Commit**: NO

---

#### ä»»åŠ¡ 5.2: æ›´æ–°ä¾èµ–æ³¨å…¥

**What to do**:
- ä¿®æ”¹ `src/api/dependencies.py`
- æ·»åŠ å‘é‡æœåŠ¡çš„å¯¼å…¥è¯­å¥
- æ·»åŠ  `get_embedding_service()` å‡½æ•°ï¼ˆä½¿ç”¨ @lru_cacheï¼‰
- æ·»åŠ  `get_vector_store()` å‡½æ•°ï¼ˆä½¿ç”¨ @lru_cacheï¼‰
- æ·»åŠ  `get_retrieval_service()` å‡½æ•°ï¼ˆä½¿ç”¨ @lru_cacheï¼‰

**Must NOT do**:
- ä¸è¦ä¿®æ”¹ç°æœ‰çš„æœåŠ¡ä¾èµ–ï¼ˆget_upload_service ç­‰ï¼‰
- ä¸è¦ç§»é™¤ @lru_cache è£…é¥°å™¨

**Recommended Agent Profile**:
- **Category**: `quick`
- **Skills**: `[]`
- **Reasoning**: ç®€å•çš„ä¾èµ–æ³¨å…¥æ·»åŠ 

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 5 Sequential
- **Blocks**: Wave 6
- **Blocked By**: Wave 1-4

**References**:

**Pattern References**:
- `src/api/dependencies.py:11-25` - ç°æœ‰çš„ lru_cache æ¨¡å¼
- `src/api/dependencies.py:11` - @lru_cache è£…é¥°å™¨ä½¿ç”¨ç¤ºä¾‹

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
from src.api.dependencies import (
    get_embedding_service,
    get_vector_store,
    get_retrieval_service
)

# Test singleton pattern
service1 = get_embedding_service()
service2 = get_embedding_service()
print(f'Singleton test: {service1 is service2}')
assert service1 is service2, 'FAIL: Should be same instance'
print('PASS: EmbeddingService is singleton')

store1 = get_vector_store()
store2 = get_vector_store()
assert store1 is store2, 'FAIL: VectorStore should be singleton'
print('PASS: VectorStore is singleton')

retrieval1 = get_retrieval_service()
retrieval2 = get_retrieval_service()
assert retrieval1 is retrieval2, 'FAIL: RetrievalService should be singleton'
print('PASS: RetrievalService is singleton')

# Verify dependencies
assert retrieval1.vector_store is store1, 'FAIL: RetrievalService should use same VectorStore'
print('PASS: Dependencies correctly injected')
"

# Expected output:
# singleton test: True
# PASS: EmbeddingService is singleton
# PASS: VectorStore is singleton
# PASS: RetrievalService is singleton
# PASS: Dependencies correctly injected
```

**Commit**: NO

---

### Wave 6: åˆ›å»ºæ£€ç´¢ API ç«¯ç‚¹

#### ä»»åŠ¡ 6.1: åˆ›å»ºæ£€ç´¢ API è·¯ç”±

**What to do**:
- åˆ›å»º `src/api/routes/retrieval.py`
- åˆ›å»º `SearchRequest` Pydantic æ¨¡å‹
- åˆ›å»º `SearchResult` Pydantic æ¨¡å‹
- åˆ›å»º `SearchResponse` Pydantic æ¨¡å‹
- å®ç° `/api/retrieval/search` POST ç«¯ç‚¹
- å®ç° `/api/retrieval/search-with-scores` POST ç«¯ç‚¹
- å®ç° `/api/retrieval/stats` GET ç«¯ç‚¹

**Must NOT do**:
- ä¸è¦ä½¿ç”¨ä¸­æ–‡å­—æ®µæè¿°ï¼ˆä½¿ç”¨è‹±æ–‡ï¼‰
- ä¸è¦ç¡¬ç¼–ç ç«¯ç‚¹è·¯å¾„ï¼ˆä½¿ç”¨å¸¸é‡æˆ–é…ç½®ï¼‰
- ä¸è¦å®ç°å¤æ‚çš„è¿‡æ»¤é€»è¾‘ï¼ˆåŸºç¡€çš„å…ƒæ•°æ®è¿‡æ»¤å³å¯ï¼‰

**Recommended Agent Profile**:
- **Category**: `visual-engineering`
- **Skills**: `["frontend-ui-ux"]`
- **Reasoning**: API è·¯ç”±å®ç°ï¼Œéœ€è¦è‰¯å¥½çš„ API è®¾è®¡å’Œ Pydantic æ¨¡å‹

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 6 Sequential
- **Blocks**: None (final wave)
- **Blocked By**: Wave 1-5

**References**:

**Pattern References**:
- `src/api/routes/upload.py:17-52` - API è·¯ç”±ç»“æ„æ¨¡å¼
- `src/api/routes/upload.py:20-52` - POST ç«¯ç‚¹å®ç°æ¨¡å¼
- `src/schemas/upload.py:5-46` - Pydantic æ¨¡å‹å®šä¹‰æ¨¡å¼

**API/Type References**:
- `fastapi.APIRouter` - è·¯ç”±å™¨ç±»
- `fastapi.Depends` - ä¾èµ–æ³¨å…¥
- `pydantic.BaseModel` - åŸºç¡€æ¨¡å‹ç±»
- `pydantic.Field` - å­—æ®µå®šä¹‰

**Acceptance Criteria**:

**Automated Verification (using Bash + Playwright)**:
```bash
# Agent executes:
echo "Starting FastAPI server..."
python -m uvicorn src.app:app --host 0.0.0.0 --port 8000 &
SERVER_PID=$!
sleep 5  # Wait for server to start

# Test search endpoint
echo "Testing /api/retrieval/search..."
curl -X POST 'http://localhost:8000/api/retrieval/search' \
  -H 'Content-Type: application/json' \
  -d '{
    "query": "Python programming",
    "k": 3
  }' > /tmp/search_response.json

# Verify response
python -c "
import json
with open('/tmp/search_response.json', 'r') as f:
    response = json.load(f)
print(f'Status: {response.get(\"query\")}')
print(f'Total: {response.get(\"total\")}')
print(f'Results: {len(response.get(\"results\", []))}')
assert response.get('total') >= 0, 'FAIL: Total should be non-negative'
assert 'results' in response, 'FAIL: Missing results field'
print('PASS: /api/retrieval/search works')
"

# Test stats endpoint
echo "Testing /api/retrieval/stats..."
curl -X GET 'http://localhost:8000/api/retrieval/stats' > /tmp/stats_response.json

python -c "
import json
with open('/tmp/stats_response.json', 'r') as f:
    response = json.load(f)
print(f'Status: {response.get(\"status\")}')
assert 'stats' in response, 'FAIL: Missing stats field'
stats = response.get('stats', {})
assert 'total_vectors' in stats, 'FAIL: Missing total_vectors'
print(f'Total vectors: {stats.get(\"total_vectors\")}')
print('PASS: /api/retrieval/stats works')
"

# Cleanup
kill $SERVER_PID
echo "Server stopped"
"

# Expected output:
# Starting FastAPI server...
# ...
# Status: Python programming
# Total: 3
# Results: 3
# PASS: /api/retrieval/search works
# Status: success
# Total vectors: 4
# PASS: /api/retrieval/stats works
# Server stopped
```

**Evidence to Capture**:
- [ ] API å“åº” JSON ä¿å­˜åœ¨ `/tmp/search_response.json`
- [ ] API å“åº” JSON ä¿å­˜åœ¨ `/tmp/stats_response.json`
- [ ] æœåŠ¡å™¨å¯åŠ¨æ—¥å¿—
- [ ] æœåŠ¡å™¨åœæ­¢æ—¥å¿—

**Commit**: NO (Wait for all waves to complete)

---

### Wave 7: æ›´æ–°é…ç½®å’Œæ³¨å†Œè·¯ç”±

#### ä»»åŠ¡ 7.1: æ›´æ–°é…ç½®æ–‡ä»¶

**What to do**:
- ä¿®æ”¹ `config.py`
- æ·»åŠ  `faiss_index_path: str` å­—æ®µï¼ˆé»˜è®¤ "./data/faiss_index"ï¼‰
- æ·»åŠ  `faiss_dimension: int` å­—æ®µï¼ˆé»˜è®¤ 1536ï¼‰
- ç¡®ä¿ `dashscope_api_key: str` å­—æ®µå­˜åœ¨ï¼ˆä» .env è¯»å–ï¼‰
- ç¡®ä¿ `dashscope_embedding_model: str` å­—æ®µå­˜åœ¨ï¼ˆé»˜è®¤ "text-embedding-v2"ï¼‰

**Must NOT do**:
- ä¸è¦ä¿®æ”¹ç°æœ‰é…ç½®å­—æ®µ
- ä¸è¦æ·»åŠ ä¸å¿…è¦çš„é…ç½®é¡¹

**Recommended Agent Profile**:
- **Category**: `quick`
- **Skills**: `[]`
- **Reasoning**: ç®€å•çš„é…ç½®æ·»åŠ 

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 7 Sequential (with Task 7.2)
- **Blocks**: None
- **Blocked By**: Wave 1-6

**References**:

**Pattern References**:
- `config.py` - ç°æœ‰é…ç½®æ¨¡å¼
- `chain/memory/faiss_mem.py:23-25` - FAISS ç›¸å…³é…ç½®å¸¸é‡

**Acceptance Criteria**:

**Automated Verification (using Bash - Python)**:
```bash
# Agent executes:
python -c "
from config import settings

# Verify FAISS config
assert hasattr(settings, 'faiss_index_path'), 'FAIL: Missing faiss_index_path'
print(f'faiss_index_path: {settings.faiss_index_path}')
assert settings.faiss_index_path == './data/faiss_index', 'FAIL: Wrong default value'
print('PASS: FAISS index path configured')

assert hasattr(settings, 'faiss_dimension'), 'FAIL: Missing faiss_dimension'
print(f'faiss_dimension: {settings.faiss_dimension}')
assert settings.faiss_dimension == 1536, 'FAIL: Wrong dimension'
print('PASS: FAISS dimension configured')

# Verify DashScope config
assert hasattr(settings, 'dashscope_api_key'), 'FAIL: Missing dashscope_api_key'
print(f'dashscope_api_key: {settings.dashscope_api_key[:10]}...')  # Only show prefix
assert len(settings.dashscope_api_key) > 0, 'FAIL: API key is empty'
print('PASS: DashScope API key configured')

assert hasattr(settings, 'dashscope_embedding_model'), 'FAIL: Missing dashscope_embedding_model'
print(f'dashscope_embedding_model: {settings.dashscope_embedding_model}')
print('PASS: All configurations correct')
"

# Expected output:
# faiss_index_path: ./data/faiss_index
# PASS: FAISS index path configured
# faiss_dimension: 1536
# PASS: FAISS dimension configured
# dashscope_api_key: sk-xxxxx...
# PASS: DashScope API key configured
# dashscope_embedding_model: text-embedding-v2
# PASS: All configurations correct
```

**Commit**: NO

---

#### ä»»åŠ¡ 7.2: æ³¨å†Œæ£€ç´¢è·¯ç”±

**What to do**:
- ä¿®æ”¹ `src/api/routes/__init__.py`
- æ·»åŠ  `retrieval_router` çš„å¯¼å…¥å’Œå¯¼å‡º
- ä¿®æ”¹ `src/app.py`
- å¯¼å…¥ `retrieval_router`
- è°ƒç”¨ `app.include_router(retrieval_router)`

**Must NOT do**:
- ä¸è¦ä¿®æ”¹ç°æœ‰çš„è·¯ç”±æ³¨å†Œ
- ä¸è¦æ”¹å˜è·¯ç”±é¡ºåº

**Recommended Agent Profile**:
- **Category**: `quick`
- **Skills**: `[]`
- **Reasoning**: ç®€å•çš„è·¯ç”±æ³¨å†Œæ·»åŠ 

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 7 Sequential
- **Blocks**: None
- **Blocked By**: Wave 1-6

**References**:

**Pattern References**:
- `src/api/routes/__init__.py:1-5` - ç°æœ‰è·¯ç”±å¯¼å…¥æ¨¡å¼
- `src/app.py:65-66` - ç°æœ‰è·¯ç”±æ³¨å†Œæ¨¡å¼

**Acceptance Criteria**:

**Automated Verification (using Bash + Playwright)**:
```bash
# Agent executes:
echo "Starting FastAPI server..."
python -m uvicorn src.app:app --host 0.0.0.0 --port 8000 &
SERVER_PID=$!
sleep 5  # Wait for server to start

# Test that retrieval routes are accessible
echo "Testing route registration..."

# Test retrieval stats endpoint
curl -X GET 'http://localhost:8000/api/retrieval/stats' > /tmp/test_route.json

python -c "
import json
with open('/tmp/test_route.json', 'r') as f:
    response = json.load(f)
assert response.get('status') == 'success', 'FAIL: Route not registered correctly'
print('PASS: Retrieval routes registered and accessible')
"

# Test OpenAPI docs
curl -s 'http://localhost:8000/openapi.json' | python -c "
import sys, json
data = json.load(sys.stdin)
paths = data.get('paths', {})

# Check if retrieval endpoints exist
assert '/api/retrieval/search' in paths, 'FAIL: Missing /api/retrieval/search'
print('PASS: /api/retrieval/search in OpenAPI')
assert '/api/retrieval/stats' in paths, 'FAIL: Missing /api/retrieval/stats'
print('PASS: /api/retrieval/stats in OpenAPI')

# Verify tags
tags = [tag.get('name') for tag in data.get('tags', [])]
assert 'æ£€ç´¢æœåŠ¡' in tags, 'FAIL: Missing æ£€ç´¢æœåŠ¡ tag'
print('PASS: Retrieval tag present')
"

# Cleanup
kill $SERVER_PID
echo "Server stopped"
"

# Expected output:
# PASS: Retrieval routes registered and accessible
# PASS: /api/retrieval/search in OpenAPI
# PASS: /api/retrieval/stats in OpenAPI
# PASS: Retrieval tag present
# Server stopped
```

**Evidence to Capture**:
- [ ] è·¯ç”±æµ‹è¯•å“åº”
- [ ] OpenAPI schema éªŒè¯æ—¥å¿—
- [ ] æœåŠ¡å™¨å¯åŠ¨å’Œåœæ­¢æ—¥å¿—

**Commit**: NO

---

#### ä»»åŠ¡ 7.3: å®‰è£… FAISS-CPU ä¾èµ–

**What to do**:
- ä¿®æ”¹ `requirements.txt` æˆ–é¡¹ç›®ä¾èµ–æ–‡ä»¶
- æ·»åŠ  `faiss-cpu` ä¾èµ–
- å¦‚æœä½¿ç”¨ `pyproject.toml`ï¼Œæ·»åŠ åˆ° dependencies

**Must NOT do**:
- ä¸è¦æ·»åŠ  `faiss-gpu`ï¼ˆç”¨æˆ·æŒ‡å®š CPU ç‰ˆæœ¬ï¼‰
- ä¸è¦ä¿®æ”¹å…¶ä»–ä¾èµ–

**Recommended Agent Profile**:
- **Category**: `quick`
- **Skills**: `[]`
- **Reasoning**: ç®€å•çš„ä¾èµ–æ·»åŠ 

**Parallelization**:
- **Can Run In Parallel**: NO
- **Parallel Group**: Wave 7 Sequential
- **Blocks**: None
- **Blocked By**: Wave 1-6

**References**:

**Pattern References**:
- æŸ¥çœ‹é¡¹ç›®ç°æœ‰çš„ä¾èµ–æ–‡ä»¶æ ¼å¼ï¼ˆ`requirements.txt`, `pyproject.toml`, æˆ– `setup.py`ï¼‰

**Acceptance Criteria**:

**Automated Verification (using Bash)**:
```bash
# Agent executes:
pip install faiss-cpu

# Verify installation
python -c "
import faiss
print(f'FAISS version: {faiss.__version__}')
print('PASS: FAISS-CPU installed successfully')

# Verify CPU backend
import faiss.swigfaiss as swigfaiss
index = swigfaiss.IndexFlatL2(1536)
print(f'Index created: {type(index)}')
print('PASS: FAISS CPU backend works')
"

# Expected output:
# FAISS version: 1.x.x
# PASS: FAISS-CPU installed successfully
# Index created: <class 'faiss.swigfaiss.IndexFlatL2'>
# PASS: FAISS CPU backend works
```

**Commit**: NO (Wait for all waves to complete)

---

## ğŸ“Š æ€»ä½“éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] æ–‡æ¡£ä¸Šä¼ åè‡ªåŠ¨å‘é‡åŒ–å¹¶å­˜å‚¨åˆ° FAISS
- [ ] å¯ä»¥é€šè¿‡ `/api/retrieval/search` è¿›è¡Œè¯­ä¹‰æœç´¢
- [ ] æ£€ç´¢ç»“æœåŒ…å«ç›¸å…³æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®
- [ ] `/api/retrieval/stats` è¿”å›ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯

### æŠ€æœ¯éªŒæ”¶
- [ ] æ‰€æœ‰æœåŠ¡ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼ˆ@lru_cacheï¼‰
- [ ] ä¾èµ–æ³¨å…¥æ­£ç¡®é…ç½®
- [ ] å‘é‡åŒ–æ­¥éª¤é›†æˆåˆ° DocumentService
- [ ] FAISS ç´¢å¼•æŒä¹…åŒ–åˆ°ç£ç›˜

### æ€§èƒ½éªŒæ”¶
- [ ] å•ä¸ªæ–‡æ¡£åµŒå…¥æ—¶é—´ < 500ms
- [ ] æ£€ç´¢å“åº”æ—¶é—´ < 100ms (k=5)
- [ ] æ”¯æŒæ‰¹é‡åµŒå…¥

---

## ğŸ¯ å…³é”®ä¾èµ–å…³ç³»

```
Wave 1 (ç±»å‹å®šä¹‰)
  â†“
Wave 2 (åµŒå…¥æœåŠ¡) â† ä¾èµ– config.py
  â†“
Wave 3 (å‘é‡å­˜å‚¨) â† ä¾èµ– Wave 1-2
  â†“
Wave 4 (ç´¢å¼•/æ£€ç´¢) â† ä¾èµ– Wave 1-3
  â†“
Wave 5 (é›†æˆ) â† ä¾èµ– Wave 1-4
  â†“
Wave 6 (API) â† ä¾èµ– Wave 1-5
  â†“
Wave 7 (é…ç½®å’Œè·¯ç”±) â† ä¾èµ– Wave 1-6
```

---

## ğŸ“ é‡è¦æé†’

1. **FAISS-CPU å®‰è£…**: ç¡®ä¿åœ¨ä»»åŠ¡ 7.3 ä¸­æ­£ç¡®å®‰è£… `faiss-cpu`
2. **API Key é…ç½®**: ç¡®ä¿ `.env` æ–‡ä»¶ä¸­æœ‰ `DASHSCOPE_API_KEY`
3. **ç›®å½•åˆ›å»º**: FAISS ç´¢å¼•ç›®å½•ä¼šè‡ªåŠ¨åˆ›å»ºåœ¨ `./data/faiss_index`
4. **å¼‚å¸¸å¤„ç†**: å‘é‡åŒ–å¤±è´¥ä¸åº”é˜»å¡æ–‡æ¡£å¤„ç†ä¸»æµç¨‹
5. **å•ä¾‹æ¨¡å¼**: æ‰€æœ‰æœåŠ¡ç±»éƒ½ä½¿ç”¨ `@lru_cache(maxsize=1)`

---

## âœ… å‡†å¤‡æ‰§è¡Œ

æœ¬å·¥ä½œè®¡åˆ’å·²åŒ…å«ï¼š
- âœ… 7 ä¸ª Waveï¼Œå…± 15 ä¸ªè¯¦ç»†ä»»åŠ¡
- âœ… æ¯ä¸ªä»»åŠ¡çš„å®Œæ•´ä»£ç ç¤ºä¾‹
- âœ… è‡ªåŠ¨åŒ–éªŒæ”¶æ ‡å‡†ï¼ˆä½¿ç”¨ Bash + Python/Playwrightï¼‰
- âœ… æ¨èçš„ Agent Profile å’ŒæŠ€èƒ½
- âœ… è¯¦ç»†çš„å¼•ç”¨å’Œæ¨¡å¼å‚è€ƒ
- âœ… æ˜ç¡®çš„ä¾èµ–å…³ç³»å’Œå¹¶è¡ŒåŒ–ç­–ç•¥

**ä¸‹ä¸€æ­¥**: è¿è¡Œ `/start-work` å¼€å§‹æ‰§è¡Œï¼
